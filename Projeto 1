#Trabalho 1 - Inteligência Computacional
#Nome:Felipe Pinto Marinho
#Matrícula:502661
#Data:21/04/2022

#Carregando algumas bibliotecas relevantes
library(plotly)
library(ggplot2)
library(ggExtra)
library(ggthemes)
library(gridExtra)
library(caret)
library(glmnet)
library(MASS)
library(Renvlp)
library(ggforce)

#Pré-processamento
aero = aerogerador
fix(aero)
names(aero) = c("velocidade", "Potência")

#Representação gráfica
#Gráfico de dispersão
attach(aero)
p = ggplot(aero, aes(x=velocidade, y=Potência, color = Potência)) +
  geom_point() +
  theme(legend.position="none") +xlab("velocidade(m/s") + ylab("Potência(W)") + theme(axis.title = element_text(size=20,face="bold"), plot.title = element_text(size=20, face="bold"), axis.text = element_text(size = 20))+ theme_classic()

p
p1 =  ggMarginal(p, type="histogram", fill = "slateblue")
p1

#Função para calcular diversas métricas de erro
métricas=function(Y_estimado,Y_real){
  MBE=mean(Y_real-Y_estimado)
  print(MBE)
  MAE=mean(abs(Y_real-Y_estimado))
  print(MAE)
  RMSE=sqrt(mean((Y_real-Y_estimado)^2))
  print(RMSE)
  rRMSE=((RMSE)/mean(Y_real))*100
  print(rRMSE)
  SSE=sum((Y_real-Y_estimado)^2)
  SSTO=sum((Y_real-mean(Y_real))^2)
  R2=1-(SSE/SSTO)
  print(R2)
  
  erro = list(RMSE, R2)
  names(erro) = c("RMSE", "R2")
  return(erro)
  
}

#Separação conjunto de treino e teste
set.seed(2)
treino = sample(1:nrow(aero), 0.7*nrow(aero))
aeroTreino = aero[treino, -c(7, 8, 11, 12, 13)]
aeroTeste = aero[-treino, -c(7, 8, 11, 12, 13)]
velTreino = aero$velocidade[treino]
potTreino = aero$Potência[treino]
potTeste = aero$Potência[-treino]

#Definição do treino
train.control = trainControl(method = "cv", number = 5)
names(train.control)
train.control$number

#Determinação das fórmula (dataset parede solar)
n = names(aero)
f = as.formula(paste("Potência ~", paste(n[!n %in% "Potência"], collapse="+")))
f

#Ajuste de uma regressão linear múltipla padrão utilizando a biblioteca Caret
LM = train(f, aeroTreino, method = "lm", trControl=train.control, preProcess=c("center", "scale"))
potHat = predict(LM, aeroTeste)
métricas(potHat, potTeste)

#Ajuste de uma regressão linear múltipla regularizada
#Ridge
#Regressão Ridge
Ridge = function(lambda, x, y){
  
  #Estimação da matriz dos coeficientes
  B = ginv(t(x) %*% x + lambda*diag(ncol(x))) %*% t(x) %*% y
  
  return(B)
}

#Estimação do parâmetro lambda por meio de hold-out
grid = 10^seq(-1, -3, length = 50)
RMSE = 0
R2 = 0
xT = cbind(rep(1, nrow(aeroTreino)), aeroTreino$velocidade)
xTest = cbind(rep(1, nrow(aeroTeste)), aeroTeste$velocidade)

for (l in grid) {
  
  #divisão treino e teste para hold-out
  tr = sample(1:nrow(aeroTreino), 0.7*nrow(aeroTreino))
  xtre = as.matrix(xT[tr, ])
  ytre = as.matrix(potTreino[tr])
  
  #Obtenção do RMSE
  Bhat = Ridge(l, xtre, ytre)
  yhat = as.matrix(xT[-tr, ]) %*% Bhat
  RMSE = cbind(RMSE, métricas(yhat, potTreino[-tr])$RMSE)
  R2 = cbind(R2, métricas(yhat, potTreino[-tr])$R2)
}

RMSE = RMSE[-1]
R2 = R2[-1]
par(mfrow=c(1,2))
plot(x = grid, y = RMSE, type = "b", xlab = "Lambda", ylab = "RMSE", pch = 20, lwd = 3, cex = 1.5 ,bty = 'L', cex.lab = 1.5, col = "slateblue") 
plot(x = grid, y = R2, type = "b", xlab = "Lambda", ylab = "R²", pch = 6, lwd = 3, cex = 1.5 ,bty = 'L', cex.lab = 1.5, col = "black")
grid[which.min(RMSE)]
grid[which.max(R2)]
lambdaOtim = grid[which.max(R2)]

#Estimação dos coeficientes
Bhat = Ridge(lambdaOtim, xT, potTreino)

#Estimação das saídas pelo Ridge
yhat = xTest %*% Bhat

métricas(yhat, potTeste)

#Modelo de envelopes
dim = u.xenv(as.matrix(aeroTreino$velocidade), as.matrix(potTreino))

par(mfrow = c(1,2))
plot(1:length(dim$aic.seq), dim$aic.seq, type = "b", col = "deepskyblue4", main = "u x AIC", xlab = "u", ylab = "AIC", pch = 20, lwd = 4, cex = 1 ,bty = 'L', cex.lab = 1.5)
plot(1:length(dim$bic.seq), dim$bic.seq, type = "b", col = "red", main = "u x BIC", xlab = "u", ylab = "BIC", pch = 20, lwd = 4, cex = 1 ,bty = 'L', cex.lab = 1.5)
dim$u.bic
dim$u.aic
u_otimo = dim$u.bic

#Ajuste do modelo de envelope para os preditores
EP = xenv(aeroTreino$velocidade, potTreino, u_otimo)

##Previsão no teste
Y_hat_envelope = rep(0, nrow(aeroTeste))
for (k in 1:nrow(aeroTeste)) {
  Y_hat_envelope[k] = pred.xenv(EP, aeroTeste[k, -2])$value
}

métricas(Y_hat_envelope, potTeste)

#Regresso polinomial
attach(aero)
RMSE_poli = 0
R2_poli = 0

for (i in 1:10) {
  
  #divisão treino e teste para hold-out
  tr = sample(1:nrow(aeroTreino), 0.7*nrow(aeroTreino))
  
  #Desempenho
  pol = lm(H_10~poly(velTreino, i), data = aeroTreino[tr, ])
  yhat = predict(pol,list(ent_b = velTreino[-tr]))
  RMSE_poli = cbind(RMSE_poli, métricas(yhat, potTreino[-tr])$RMSE)
  R2_poli = cbind(R2_poli, métricas(yhat, potTreino[-tr])$R2)
}

RMSE_poli = RMSE_poli[-1] 
R2_poli = R2_poli[-1]

par(mfrow=c(1,2))
plot(x = 1:10, y = RMSE_poli, type = "b", xlab = "Grau", ylab = "RMSE", pch = 20, lwd = 3, cex = 1.5 ,bty = 'L', cex.lab = 1.5, col = "slateblue") 
plot(x = 1:10, y = R2_poli, type = "b", xlab = "Grau", ylab = "R²", pch = 6, lwd = 3, cex = 1.5 ,bty = 'L', cex.lab = 1.5, col = "black")

pol = lm(Potência~poly(velocidade, 7), data = aeroTreino)
yhat = predict(pol,list(velocidade = velTreino))
métricas(yhat, potTeste)

#Regressao local
grid_loc = 10^seq(0, -1, length = 50)
RMSE_loc = 0
R2_loc = 0

for (j in grid_loc) {
  
  #divisão treino e teste para hold-out
  tr = sample(1:nrow(aeroTreino), 0.7*nrow(aeroTreino))
  
  #Desempenho
  loc = loess(H_10~ent_b, span = j, data = aeroTreino[tr,])
  yhat_loc = predict(loc, aeroTreino[-tr,])
  RMSE_loc = cbind(RMSE_loc, métricas(yhat_loc, potTreino[-tr])$RMSE)
  R2_loc = cbind(R2_loc, métricas(yhat_loc, potTreino[-tr])$R2)
  
}

RMSE_loc_n = RMSE_loc[which(is.na(RMSE_loc) == F)]
R2_loc_n = R2_loc[which(is.na(R2_loc) == F)]
RMSE_loc_n = RMSE_loc_n[-1]
R2_loc_n = R2_loc_n[-1]

r = grid_loc[which(is.na(RMSE_loc) == F)]
r = r[-1]

par(mfrow=c(1,2))
plot(x = r, y = RMSE_loc_n, type = "b", xlab = "s", ylab = "RMSE", pch = 20, lwd = 3, cex = 1.5 ,bty = 'L', cex.lab = 1.5, col = "slateblue") 
plot(x = r, y = R2_loc_n, type = "b", xlab = "s", ylab = "R²", pch = 6, lwd = 3, cex = 1.5 ,bty = 'L', cex.lab = 1.5, col = "black")
s = r[which.min(RMSE_loc_n)]

loc = loess(Potência~velocidade, span = s, data = aeroTreino)
yhat_loc = predict(loc, aeroTeste)
métricas(yhat_loc, potTeste)

################################################################################
#Sistema de Inferência Fuzzy - Mamdani
ordenamento = sort.int(velocidade, index.return = T) 
names(ordenamento)
x = ordenamento$x
y = Potência[ordenamento$ix]

#número dae funções de pertinência
Nmf = 5

#Valores iniciais dos parâmetros das funções de pertinência
centers = c(4, 6.5, 9.19, 11.5, 14)
powerw= c(20, 134, 270, 480, 508)

plot(x = velocidade, y = Potência, main = "Curva de Potência do Aerogerador", lwd = 2, xlab = "velocidade (m/s)", ylab = "Potência (W)", cex.lab = 1.3, cex.axis = 1.3, xlim = c(0,19), ylim = c(0,700))
points(centers, powerw, pch = 20, col = "red", cex = 2)
legend("topleft", legend = c("observações", "pontos de suporte", "muito baixa", "baixa", "média", "alta", "muito alta"), col = c("black", "red", "darkslategrey", "green", "blue", "brown", "orange"), pch = c(1, 20, 20, 20, 20, 20, 20), bty = "n", pt.cex = 2, cex = 1.2, text.col = "black", horiz = F , inset = c(0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1))

#dispersão para cada gaussiana
spread = 1.35

#criação de um grid para a velocidade
xx = velocidade[-treino] #seq(from = 0.8*min(x), to = 1.2*max(x), by = 0.1)
mi = matrix(0, nrow = Nmf, ncol = length(xx))
ypred = rep(0, 5)
ypred_TS = rep(0, 5)
yhat_mamdani = rep(0, length(xx))
yhat_TS = rep(0, length(xx))

#Divisao do universo de discurso em intervalos de larguras iguais
t = c(0, 3, 6, 9, 12, 15)
fix(aero)

#funções de pertinência gaussianas para a velocidade
for (j in 1:length(xx)) {
  for (i in 1:Nmf) {
    mi[i, j] = exp(-(xx[j] - centers[i])^2/(2*(spread)^2)) #ativaçao da i-ésima regra
    ypred[i] = powerw[i] #saída predita para i-ésima regra (singleton)
    I = which(velocidade >= t[i] & velocidade < t[i+1])
    linear = lm(Potência~velocidade, data = aero[I, ])
    ypred_TS[i] = dot(linear$coefficients, c(1,xx[j]))
  }
  
  yhat_mamdani[j] = dot(ypred, mi[, j])/sum(mi[, j])
  yhat_TS[j] = dot(ypred_TS, mi[, j])/sum(mi[, j])
}


#Amplificação
K=150

#plot's das funções de pertinência
lines(xx, K*mi[1,], type = "l", col = "darkslategrey", lwd = 3)
lines(xx, K*mi[2,], type = "l", col = "green", lwd = 3)
lines(xx, K*mi[3,], type = "l", col = "blue", lwd = 3)
lines(xx, K*mi[4,], type = "l", col = "brown", lwd = 3)
lines(xx, K*mi[5,], type = "l", col = "orange", lwd = 3)

#Etapa de predição
métricas(yhat_mamdani, potTeste)
métricas(yhat_TS, potTeste)

##############################################################

#plot
resultados = cbind(yhat_loc, potTeste)
resultados = as.data.frame(resultados)

p = ggplot(resultados, aes(x=resultados$potTeste, y=resultados$yhat_loc, color = potTeste)) +
  geom_point() +
  theme(legend.position="none") +xlab("Potência Medida (W)") + ylab("Estimada (W)") + theme(
    axis.title=element_text(size=14,face="bold"))

p = p + geom_smooth(method=lm , color="black", se=FALSE)
p

# with marginal histogram
p1 = ggMarginal(p, type="histogram", fill = "slateblue")
p1 

#radar plot
modelos = c("Linear", "Ridge", "Envelope", "Polinomial", "Local", "Mamdani", "Takagi-Sugeno")
RMSE = c(28.18, 28.18, 28.18, 15.52, 15.48, 19.31, 28.41)
MBE = c(0.048, 0.038, 0.048, -0.23, -0.14, 7.20, 16.97)
MAE = c(17.86, 17.87, 17.86, 10.50, 10.47)

erros = cbind(modelos, RMSE, MBE)
erros = data.frame(erros)
rownames(erros) = modelos
fix(erros)
attach(erros)

Modelo = erros$modelos
plotMBE_RMSE = ggplot(erros, aes(x = RMSE, y = MBE), group=Modelo) + 
  geom_point(aes(shape=Modelo, color=Modelo, 
                 size=Modelo))+
  scale_shape_manual(values=c(17, 19, 18, 15, 10, 9, 8))+
  scale_color_manual(values=c('#006600','red', '#cc9900', "blue", "black", "magenta", "darkslategrey"))+
  theme(legend.position="right")+
  scale_size_manual(values=c(3,4,3,3,3,3,3))+
  # horizontal
  geom_hline(yintercept=0, color="black", size=.5) + 
  # vertical
  geom_vline(xintercept=0, color="black", size=.5)+
  coord_cartesian(xlim=c(-40,40),ylim = c(-40,40))+
  scale_x_continuous(breaks = seq(-40,40,((40+40)/5)))+
  scale_y_continuous(breaks = seq(-40,40,((40+40)/5)))+
  coord_fixed()+
  geom_circle(linetype="dashed", color = "black" ,aes(x0 = 0, y0 = 0, r = seq(0, 40, length.out = 7)),inherit.aes = FALSE)+
  theme(
    axis.title=element_text(size=14,face="bold"), plot.title = element_text(size=14,face="bold"), axis.text = element_text(size = 16))
plotMBE_RMSE

#Análise de resíduos
yhat_loc_total = predict(loc, aero)
residuos = yhat_loc_total-aero$Potência
pacf(residuos, ylab = "PACF")

classe = rep(0, nrow(aero))
classe[treino] = "treino"
classe[-treino] = "teste"
aero = cbind(aero, classe)
aero = data.frame(aero)

scatter <- ggplot(aero, aes(x = yhat_loc_total, y = residuos, color = classe)) + 
  
  geom_point() +  labs( x ="predições") 


scatter <- ggplotly(p = scatter, type = 'scatter')


violin <- aero %>%
  
  plot_ly(x = ~classe, y = ~residuos, split = ~classe, type = 'violin' )


s <- subplot(
  
  scatter,
  
  violin,
  
  nrows = 1, heights = c(1), widths = c(0.65, 0.35), margin = 0.01,
  
  shareX = TRUE, shareY = TRUE, titleX = TRUE, titleY = TRUE
  
)


layout(s, showlegend = T)

